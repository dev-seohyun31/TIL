
* 서비스의 성능은 보통 응답시간과 처리량으로 측정합니다. 두 지표는 밀접한 관계가 있으며, 응답시간이 느려지면 처리량도 자연스럽게 떨어진다. 응답시간은 4단계로 구성되는데, 로직 수행, DB 연동, 외부 API 연동, 응답 데이터 생성 및 전송입니다. 이 중 DB 연동과 외부 API가 전체 시간에서 가장 큰 비중을 차지합니다. 
* 응답 시간을 개선하는 가장 단순한 방법은 처리 시간의 병목 지점을 찾고, 그 구간에 대해 수직 확장(자원 증설) 또는 수평 확장(서버 추가)를 진행하는 것입니다. 
 * DB 커넥션 풀을 사용하면 서버와 DB가 미리 TCP 연결을 유지하고 있어서 매 요청 때마다 연결과 해제를 반복하지 않아도 됩니다. 커넥션 대기 시간을 짧게 하고, 커넥션 유휴 시간은 DB의 커넥션 타임아웃인 wait_timeout 보다 짧게 설정해야 합니다. 커넥션 수는 서비스의 동시 요청 수준에 맞춰 조정해야 합니다. 그렇지 않으면, 너무 많을 시에 DB CPU 부하가 증가하고 너무 적으면 대기시간이 늘어날 수 있습니다. 
* DB 확장이 어렵거나 부하가 집중될 경우, 캐시를 도입해 조회 속도를 높일 수 있습니다. 로컬 캐시는 같은 프로세스 메모리에 저장되어 매우 빠르지만, 서버가 여러대이면 데이터 불일치가 생길 수 있습니다. 이 때, 메시지 브로드캐스트를 사용해서 무효화 동기화가 가능합니다. 리모트 캐시는 중앙 서버 형태로 여러 인스턴스가 동일 데이터를 공유합니다. 네트워크 오버헤드가 있으나 일관성이 유지될 수 있습니다. 캐시의 적중률이 높은지 확인하고, LRU 기반의 만료 전략 설정을 잘 해두어야 합니다.
* 그 외에도 성능 개선하기 위해 응답 데이터를 압축해서 네트워크 전송량 70% 이상 절감할 수 있으며, 정적 자원은 캐시와 cdn처리할 수 있고, HTTP 헤더 설정(Cache-Control, ETag)로 클라이언트 캐시를 유도할 수 있습니다.

<br>

* 성능 문제는 대부분 비효율적인 쿼리에서 발생하는 편입니다. 
* 쿼리 실행계획으로 풀스캔 여부를 확인할 수 있고, 쿼리 비용이 많이 나올 시에는 인덱스 설계를 할 수 있습니다. 조회 패턴 순서에 맞춰서 복합 인덱스를 설계하고, 선택도가 높은 컬럼 부터 인덱스 설정, 커버링 인덱스로 테이블 접근 최소화 등을 할 수 있습니다. 인덱스는 많을수록 쓰기 성능 저하와 디스크 사용 증가를 초래하므로 최소화해야 합니다.
* 집계 쿼리 최적화를 위해 비정규화된 집계용 칼럼(likeCount, commentCount)을 둘 수도 있습니다. 이때 두 데이터를 동시에 업데이트할 경우, 트랜젝션으로 묶거나 원자적 쿼리를 사용해서 동시성 문제를 방지할 수 있습니다.
* 기존의 offset 기반 페이지네이션은 뒤로 갈수록 느려집니다. 따라서 최근에는 노프셋이라고 하여 커서 기반 페이지네이션을 사용합니다. (select * from posts where id < ? order by id desc limit 10;) 이 방식은 마지막 페이지 번호는 없고, 이전/다음 페이지 이동만 존재하는 구조로, 대규모 서비스에서 일반적입니다.
* 최신 데이터만 조회하거나, 오래된 데이터는 분리 보관하는 방식으로 성능을 유지할 수 있습니다. 쓰기 담당인 주DB와 읽기 담당인 복제DB로 읽기/쓰기를 분리할 수도 있고, 물리적으로 DB를 분할하여 독립 처리할 수 있는 샤딩을 진행할 수 있습니다. 

<br><br>

* 외부 연동은 마이크로서비스, 외부 API, 타사 연동 등에서 점점 증가하는 추세입니다. 그러나 외부 장애는 내부 장애로 전파되기 쉬우므로 다음 주의가 필요합니다.
* 타임아웃이 없으면 모든 스레드가 blocking이 되어 서버 전체가 멈출 수 있습니다. Connection Timeout은 네트워크 연결 실패 시 발생할 수 있으며, Read Timeout은 응답이 늦을 때 발생할 수 있습니다. 각각 타임아웃은 3~5초, 5~30초 정도로 짧지만 기다릴 수 있게 길게 적정 값으로 조절해야합니다.
* 400(Bad Request)는 클라이언트 오류이므로 재시도해도 실패할 확률이 높아 재시도하지 않습니다. 500대 에러는 네트워크 오류일 가능성이 있으므로 일정 간격으로 재시도가 가능합니다. 재시도는 멱등성이 보장되는 API만 1~2회 재시도합니다.
* RestTemplate, WebClient 등의 HTTP 커넥션 풀에서 최대 커넥션 수를 제한합니다. 초과 요청은 503 Service Unavailable 로 반환이 가능합니다. 이를 Rate Limiting이라 하며, 내부 서버에서 호출을 제한할 수 있습니다. (설정이 아니라?????)
* 외부 API 오류율이 일정 수준을 초과하면 호출을 중단하는 서킷 브레이커를 활용합니다. 열림 -> 반열림 -> 닫힘 상태 전환으로 자동 복구를 관리할 수 있습니다.
* DB 트랜잭션과 외부 연동은 분리하는 것이 원칙입니다. 외부 연동이 실패할 경우, Read Timeout 발생 시, 외부 서비스는 실제로 처리되었을 수 있습니다. 이 때 배치 재동기화, 성공확인 API, 성공확인 API, 취소 API 등으로 후속 보정이 필요합니다. DB가 실패하면 보상 트랜잭션 설계로 일관성을 유지해야 합니다.
* HTTP 커넥션 풀도 DB 커넥션 풀처럼 최대 커넥션 수, 대기시간, 유지 시간 등 관리를 해야합니다. 
* 외부 서비스 장애가 핵심 기능에 영향이 크다면, 해당 API를 이중화하여 한쪽 장애 시 다른 노드로 우회해야 합니다.

<br>

* 외부 연동 시 blocking 되면 스레드 고갈될 수 있습니다. 이를 방지하기 위해, 지연이 허용되는 작업은 비동기 처리로 전환합니다. 비동기에 적합한 기능으로는 푸시 알림, 포인트 지급, SMS 발송같은 작업으로, 늦게 처리되어도 문제 없거나, 재시도가 가능하고, 실패되어도 무시가능한 기능입니다.
* 별도 스레드로 호출(new Thread, ExecutorService, @Async)하여 구현할 수 있습니다. 즉, 스레드를 생성해도 되고, 스레드풀을 사용해도 되고, 스프링의 @Async 를 사용해도 됩니다. 단, 예외는 메인 스레드로 전파되지 않으므로, 비동기 함수 내부에서 반드시 try-catch로 처리해야 합니다.
* 비동기는 메시징 시스템으로도 구현할 수도 있습니다. 결합도를 낮추고 시스템 간 트래픽을 분리할 수 있는 설계로, 초당 백만건되는 대규모 트래픽엔 Kafka, 순서가 중요한 소규모 트래픽은 RabbitMQ, 경량 이벤트 처리는 Redis pub/sub 등을 활용할 수 있습니다. 메시지 생성할 때는 전송 실패 시 메시지를 무시할건지, 재시도할건지, 실패 로그를 DB에 저장 후 후처리할 것인지 메시지 유실 방지를 위한 대책을 세워야하고, DB와 트랜젝션을 꼭 분리해서 발송해야 합니다. 메시지 소비자는 중복 처리가 되지 않도록 멱등성을 보장하고, 큐 적체량을 모니터링 해야합니다.
* 전통적으로 비동기는 배치로 처리했습니다. 일정 주기로 데이터를 파일 형태로 수집하고, 소비자는 해당 파일을 읽어서 일괄 처리한 뒤 백업합니다.
* DB의 변경 로그를 기반으로 이벤트를 발행할 수도 있습니다. MSA 환경에서 서비스 간 데이터 일관성 유지에 유용하고, Kafka Connect, Debezuim 등으로 구현이 가능합니다. 이를 CDC, Change Data Capture 기술이라고 합니다.

<br>

* 서버는 항상 여러 요청이 동시에 같은 데이터를 변경할 가능성을 안고 있습니다. 이런 오류는 바로 드러나지 않아 발견하면 원인 파악도 힘들기 때문에 이런 위험성을 인지하고 개발해야 합니다. 
* 단일 프로세스에서는 (즉, 단일 서버에서) 먼저 락을 사용해서 제어할 수 있습니다. ReentrantLock으로 하나의 스레드만 접근 가능하도록 제어할 수 있고, Semaphore로 접근 가능한 스레드 수를 제한할 수 있고, ReadWriteLock으로 읽기는 동시 허용 및 쓰기는 1개만 허용할 수 있습니다. 락을 사용하지 않아도 되는 CAS 연산을 이용하여 원자적 타입을 사용할 수 있습니다. int, long 등 단일 변수 수준에서만 적용이 가능하지만 락처럼 blocking 과정이 없습니다. 컬렉션에서 동시성이 필요하다면 ConcurrentHashMap, BlockingQueue와 같이 스레드 안전한 프레임워크를 사용할 수 있고, 큐에 요청을 넣고 단일 스레드가 순차처리하는 이벤트 루프 기반 구조를 활용할 수도 있습니다.
* DB의 동시성 제어는 트랜잭션 외의 추가 방법을 제안할 수 있습니다. 비관적 잠금으로 select for update 문은 하나의 트랜젝션만 접근가능하도록 하여 외부 연동 등 트랜젝션이 길어질 때 유용합니다. 낙관적 잠금으로는 version 칼럼 비교로 충돌을 감지하고 update 결과 0이면 롤백합니다. 자바처럼 CAS 연산을 활용할 수도 있는데, update set count = count+1 문을 사용해서 락 없이 동시성을 제어할 수 있습니다.
* 분산 환경에서는 여러 프로세스가 동시 접근할 수 있는데, 이 때 분산락이 필요합니다. DB를 사용한다면 dist_lock 테이블을 생성해서 insert, update로 잠금을 관리할 수 있습니다. redis를 사용한다면 SETNX lockKey <value> PX <timeout>으로 key가 존재하지 않을 때만 atomic하게 성공하며 해제는 DEL명령으로 직접 수행하는 방향으로 구현할 수 있습니다.

<br>

* 서버 성능이 문제가 생기면 수평/수직 확장을 먼저 고려합니다. 그 다음으로 DB 쿼리나 캐시를 적용하여 성능을 개선시킬 수 있고, 마지막으로 IO 구조 자체를 개선할 수 있습니다.
* 톰캣은 기본적으로 요청당 1개의 쓰레드를 할당합니다. 트래픽이 증가하면 스레드의 스택 메모리 사용량이 요청수만큼 증가하고, IO가 대기하면서 컨택스트 스위칭 오버헤드가 증가합니다. 
* OS가 아니라 JVM이 관리하는 스레드를 사용하여 메모리 사용량이 적고 처리량이 높은 가상 스레드를 사용할 수 있습니다. 단, CPU 연산 중심의 작업에서는 실행속도가 개선되는 방법은 아닙니다. 또한, 가상 스레드 수가 플랫폼 스레드 수보다 많아야 효과가 있습니다. 
* 이 경량 스레드로도 트래픽 한계가 온다면, 논블로킹 IO로 IO 구조를 바꾸는 방법도 있습니다. 이벤트 루프가 IO 이벤트를 감지하고 핸들러가 해당 이벤트를 처리하는 방식입니다. 하나의 스레드가 수천개의 IO를 관리할 수 있어서 스레드 수가 절감되어 처리량이 늘어날 수 있습니다. 주로 netty, Nginx, Node.js, Spring WebFlux가 이런 방식으로 구현되어 있습니다. 하지만 블로킹 IO와 혼용 시 블로킹 호출이 루프를 멈추 할 수 있습니다. 예를 들어, WebFlux 내부에서 JDBC 동기 쿼리 실행 시, 전체 요청에 지연이 발생합니다. 따라서 이런 논블로킹 IO 구조에서는 비동기 API와 논블로킹 연산만 사용해야 합니다.
